# Guide d'optimisation SkyReels-V2 pour 2x RTX 5090

## üÜï MISE √Ä JOUR : Correction de l'erreur NCCL

Suite √† l'erreur NCCL/CUDA, j'ai ajout√© des corrections suppl√©mentaires et des alternatives.

## üöÄ Solution rapide

### Option 1 : GPU Unique (RECOMMAND√â - Plus stable)

```bash
# Test simple sur un seul GPU
python3 test_single_gpu.py

# Ou utiliser le script de lancement
./run_single_gpu.sh safe
```

### Option 2 : Multi-GPU avec USP (apr√®s corrections)

```bash
# Avec les corrections appliqu√©es
./run_skyreels_2gpu.sh safe
```

## üìù Fichiers modifi√©s/cr√©√©s

### Corrections appliqu√©es
- **`skyreels_v2_infer/distributed/xdit_context_parallel.py`** : 
  - Ligne 39 : float64 ‚Üí float32 (√©conomie m√©moire)
  - Ligne 69 : Correction du device pour broadcast NCCL
- **`generate_video_optimized.py`** : Script optimis√© avec gestion m√©moire
- **`test_single_gpu.py`** : Script de test GPU unique (nouveau)
- **`run_single_gpu.sh`** : Lancement sur un seul GPU (nouveau)
- **`run_skyreels_2gpu.sh`** : Script multi-GPU avec modes

### 2. Utilisation rapide

```bash
# Rendre le script ex√©cutable
chmod +x run_skyreels_2gpu.sh

# Mode SAFE (utilisation minimale de m√©moire)
./run_skyreels_2gpu.sh safe

# Mode NORMAL (√©quilibr√©)
./run_skyreels_2gpu.sh normal

# Mode QUALITY (haute qualit√©, plus de m√©moire)
./run_skyreels_2gpu.sh quality

# Mode FAST (g√©n√©ration rapide)
./run_skyreels_2gpu.sh fast
```

## üìä Comparaison des modes

| Mode | Frames | Steps | M√©moire GPU | Temps | Qualit√© |
|------|--------|-------|-------------|-------|---------|
| **safe** | 25 | 15 | ~20GB | ~2min | ‚≠ê‚≠ê‚≠ê |
| **normal** | 49 | 20 | ~25GB | ~4min | ‚≠ê‚≠ê‚≠ê‚≠ê |
| **quality** | 97 | 30 | ~30GB | ~8min | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| **fast** | 25 | 10 | ~18GB | ~1min | ‚≠ê‚≠ê |

## üõ†Ô∏è Commande manuelle personnalis√©e

Si vous voulez plus de contr√¥le :

```bash
# Exemple avec param√®tres personnalis√©s
torchrun --nproc_per_node=2 generate_video_optimized.py \
    --model_id /home/server/dev/SkyReels-V2-fork/checkpoints/14B-T2V-540P \
    --resolution 540P \
    --num_frames 35 \
    --inference_steps 18 \
    --guidance_scale 6.0 \
    --shift 8.0 \
    --fps 24 \
    --use_usp \
    --seed 42 \
    --dtype float16 \
    --offload \
    --teacache \
    --teacache_thresh 0.25 \
    --prompt "Your custom prompt here"
```

## üîß Param√®tres d'optimisation

### R√©duction de m√©moire (du plus au moins efficace)

1. **`--dtype float16`** : Utilise float16 au lieu de bfloat16 (√©conomie ~30%)
2. **`--offload`** : D√©charge certains calculs sur CPU (√©conomie ~20%)
3. **`--num_frames`** : R√©duire le nombre de frames (√©conomie proportionnelle)
4. **`--inference_steps`** : R√©duire les √©tapes (√©conomie ~10-15% par 10 steps)
5. **`--teacache`** : Active la mise en cache (√©conomie ~15-20%)

### Am√©lioration de la vitesse

1. **`--teacache --teacache_thresh 0.3`** : Acc√©l√©ration 3x avec l√©g√®re perte de qualit√©
2. **`--use_ret_steps`** : Am√©liore la vitesse avec TeaCache
3. **`--inference_steps 10`** : Moins d'√©tapes = plus rapide

## üêõ R√©solution de probl√®mes

### Erreur "CUDA out of memory"

1. **Premi√®re tentative** : Utiliser le mode `safe`
   ```bash
   ./run_skyreels_2gpu.sh safe
   ```

2. **Si √ßa ne marche toujours pas** :
   ```bash
   # Ultra safe mode
   torchrun --nproc_per_node=2 generate_video_optimized.py \
       --model_id /home/server/dev/SkyReels-V2-fork/checkpoints/14B-T2V-540P \
       --resolution 540P \
       --num_frames 17 \
       --inference_steps 10 \
       --use_usp \
       --seed 42 \
       --dtype float16 \
       --offload \
       --teacache --teacache_thresh 0.35
   ```

### V√©rifier l'utilisation GPU

```bash
# Surveiller l'utilisation en temps r√©el
watch -n 1 nvidia-smi

# Ou dans un autre terminal pendant la g√©n√©ration
nvidia-smi dmon -s mu
```

## üìà Optimisations appliqu√©es

### 1. Modification du code source
- **rope_apply** : float64 ‚Üí float32 (√©conomie significative de m√©moire)
- **autocast** : Utilisation correcte de torch.amp.autocast

### 2. Variables d'environnement
```bash
export PYTORCH_CUDA_ALLOC_CONF='expandable_segments:True,max_split_size_mb:512'
```
- Am√©liore la gestion de la fragmentation m√©moire
- Permet une allocation plus efficace

### 3. Gestion m√©moire active
- Nettoyage r√©gulier avec `gc.collect()` et `torch.cuda.empty_cache()`
- Synchronisation GPU appropri√©e

## üí° Conseils suppl√©mentaires

1. **Pour des vid√©os plus longues** : G√©n√©rez plusieurs clips courts et assemblez-les
2. **Pour 720P** : Utilisez d'abord 540P puis upscalez avec un autre mod√®le
3. **Batch processing** : Traitez plusieurs prompts en s√©quence avec le m√™me mod√®le charg√©

## üîç Monitoring

Pour surveiller l'utilisation pendant la g√©n√©ration :

```python
# Ajoutez ceci dans votre script Python
import torch

def print_gpu_memory():
    for i in range(torch.cuda.device_count()):
        print(f"GPU {i}: {torch.cuda.memory_allocated(i)/1024**3:.2f}GB / {torch.cuda.max_memory_allocated(i)/1024**3:.2f}GB")

# Appelez apr√®s chaque √©tape importante
print_gpu_memory()
```

## üìû Support

Si vous rencontrez toujours des probl√®mes apr√®s ces optimisations :

1. Essayez le mod√®le 1.3B au lieu du 14B
2. R√©duisez encore les param√®tres
3. V√©rifiez que vous avez bien les derniers drivers NVIDIA
4. Assurez-vous que rien d'autre n'utilise les GPUs

## ‚úÖ Checklist de d√©marrage

- [ ] Script rendu ex√©cutable : `chmod +x run_skyreels_2gpu.sh`
- [ ] Environnement virtuel activ√©
- [ ] Mod√®le t√©l√©charg√© dans `/home/server/dev/SkyReels-V2-fork/checkpoints/`
- [ ] 2 GPUs disponibles (v√©rifier avec `nvidia-smi`)
- [ ] Au moins 64GB de RAM syst√®me pour l'offload CPU

Bonne g√©n√©ration de vid√©os ! üé¨